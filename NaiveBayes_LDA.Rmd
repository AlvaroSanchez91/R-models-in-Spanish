---
title: 'ML I: Ejercicio de evaluación.'
author: "Álvaro Sánchez Castañeda"
date: "3 de junio de 2017"
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#EJERCICIO 1:
###Sobre la base de datos BreastCancer de la librería mlbench, realice las siguientes actividades:
###1. Construya un clasificador Naive-Bayes usando una muestra aleatoria constituida por 2/3 de la totalidad del fichero de datos.
###2. Obtenga la matriz de confusión y el porcentaje de clasificación incorrecta a partir de las instancias no usadas en la construcción del clasificador.
###3. Determine el número de predicciones correspondientes a la clase malignant.
###4. De las predicciones consideradas en el apartado anterior, determine cuántas de ellas se han obtenido con una probabilidad mayor que 0.75.

Ya que hemos estudiado conjuntamente Naive Bayes como Análisis Discriminante como clasificadores probabilísticos, parece interesante completar el ejercicio usando tambien Análisis Discriminante.

Los dos primeros puntos del ejercicio se realizarán en las secciones: Lectura de datos Y librerias, Preprocesamiento y Modelado. Las dos ultimos puntos se encuentran al final del documento, una vez construidos y evaluados los modelos.

## Lectura de datos y librerias.

###Librerias.
```{r, message=FALSE, warning=FALSE}
library(ggplot2)#graficas
library(GGally)#graficas
library(corrplot)#correlaciones
library(mlbench)#datos
library(MASS)#LDA
library(e1071)#Naive Bayes
library(ROCR)#ROC y AUC
```

### Datos.
```{r, message=FALSE, warning=FALSE}
data("BreastCancer")
datos<-BreastCancer[,-1]#Eliminamos identidad
```
A priori, las variables de esta base de datos son de tipo factor con etiquetas correspondientes a numeros enteros, ademas, se indica que las etiquetas preservan un orden. No suele ser lo habitual, pero dado que mantienene el orden podría ser razonable tomar dichas variables como numericas usando los numeros enteros de sus etiquetas.

Transformemos las variables a numéricas.
```{r, message=FALSE, warning=FALSE}
datos_num <- data.frame(sapply(datos[, c(1:9)], as.numeric))
datos_num$Class=datos$Class
```



## Preprocesamiento.

### Variable objetivo.
Ya que nuestra variable objetivo es binaria, la transformaremos a una variable lógica que indique si el tumor es, o no, maligno.

```{r}
datos$Class= datos$Class=='malignant'
datos_num$Class=datos$Class
```



### Valores perdidos.
Busquemos los valores perdidos de nuestros datos.
```{r}
apply(is.na(datos),2,sum)
which(apply(is.na(datos),1,sum)>0)
datos=datos[-which(apply(is.na(datos),1,sum)>0),]
datos_num=datos_num[-which(apply(is.na(datos_num),1,sum)>0),]
```
Vemos que son pocos, de modo que simplemente han sido eliminados.

### Partición train test.

Dividiremos el conjunto en dos partes, tal como se especifica en el ejercicio.
```{r}
set.seed(123)
n<- nrow(datos)
nent<- ceiling((2/3)*n)
indient=sample(n,nent)
train=datos[indient,]
test=datos[-indient,]
train_num=datos_num[indient,]
test_num=datos_num[-indient,]
```



### Tipificación.

Reescalemos los datos transformados a numéricos basandonos unicamente el el conjunto de entrenamiento.

```{r}
train_trans=data.frame(scale(train_num[1:9]))
test_trans=data.frame(scale(test_num[1:9], center =apply(train_num[1:9],2,mean),
            scale = apply(train_num[1:9],2,sd)))
train_trans$Class=train_num$Class
test_trans$Class=test_num$Class
```


## Breve análisis exploratorio.

### Hipótesis.

En el desarrollo del método Naive Bayes, asumimos que nuestras variables son independientes, veamos la matriz de correlaciones de nuestros datos (transformados a numéricos) para ver si esto parece razonable.

```{r}
corrplot(cor(datos_num[1:9]), addCoef.col = "black",tl.cex=0.7,number.cex=0.7)
```

Algunas correlaciones son muy altas, no podemos asumír independencia, pero el modelo podría funcionar bien apesar de esto. Veamos las nuves de puntos para cada par de variables de nuestros datos transformados a numéricos.


```{r, message=FALSE, warning=FALSE}
ggpairs(datos_num, aes(color=Class), columns=1:9,
        upper=list(continuous='points'),axisLabels='none')
```

A simple vista parece que los dos grupos están bien diferenciados, pero no parece que cada subclase sigua una distribución normal (hipotesis necesaria para Análisis Discriminante).



Si los dos grupos sigguiesen normales, entonces sus marginales también. Contrastemos esto mediante test de Shapiro Wilk.

```{r}
for (i in 1:9){
  print(shapiro.test(datos_num[datos_num$Class==T,i])$p.value)
}
for (i in 1:9){
  print(shapiro.test(datos_num[datos_num$Class==F,i])$p.value)
}
```

No se haceptan las hipótesis de normalidad, pero los modelos podrían dar buenos resultados independientemente de esto.




## Modelado.

### Funcion de evaluación.
Antes de ajustar los modelos, definamos una función que nos devuelva difrerentes medidas de ajuste de dichos modelos sobre el conjunto test.

```{r}

evaluacion=function(reales=test$Class,probabilidades_pred,titulo='modelo',plot_roc_mc=T){
  pred=probabilidades_pred>0.5
  mc=table(pred,reales)
  precision=sum(diag(mc))/sum(mc)
  sensibilidad=prop.table(mc,2)[2,2]
  especificidad=prop.table(mc,2)[1,1]
  
  #resto uno, la siguiente función esta tomando TRUE como FALSE y viceversa
  prediobj<-prediction(1-probabilidades_pred,as.numeric(reales))
  if (plot_roc_mc){
    
    curva_aux=performance(prediobj, "tpr","fpr")
    curva=cbind.data.frame(curva_aux@x.values[[1]],curva_aux@y.values[[1]])
    colnames(curva)=c('x','y')
    #invierto x e y, pues la anterior función tomaba TRUE como FALSE y viceversa
    print(ggplot(curva,aes(y,x))+geom_line(col='red4',size=1)+geom_abline(intercept = 0,size=0.8)+xlab('1-true benign ratio')+
    ylab('True malignant ratio')+ggtitle(titulo)
)
    
    print(mc)
  }

auc<- 1- as.numeric(performance(prediobj,"auc")@y.values)
medidas=t(data.frame(c(precision,sensibilidad,especificidad,auc)))
row.names(medidas)=titulo
colnames(medidas)=c('precision','sensibilidad','especificidad','auc')
return(list(medidas,mc))
  
}
```




### Naive Bayes variables originales.

```{r}
NaiveBayes = naiveBayes(formula = Class ~ .,data=train)#Ajustamos modelo.
prob=predict(NaiveBayes,test,type = 'raw')[,2]#Estimamos probabilidades de test.
```

Podemos guardar las distintas medidas de ajuste (sobre test) de los modelos que ajustemos, para poder compararlos.
```{r}
(evaluaciones=evaluacion(test$Class,prob,'NaiveBayes')[[1]])
```
 Observando la matriz de confusión, la curva roc y las distintas medidas, deducimos que tenemos un buen ajuste.
 

 
### Naive Bayes variables numéricas.
```{r}
NaiveBayes_num = naiveBayes(formula = Class ~ .,data=train_num)#Ajustamos modelo.
prob=predict(NaiveBayes_num,test_num,type = 'raw')[,2]#Estimamos probabilidades de test.
(evaluaciones=rbind(evaluaciones,evaluacion(test_num$Class,prob,'NaiveBayes_num')[[1]]))
```

Usando las variables transformadas a numeros enteros, obtenemos una mayor precisión sobre la clase malignant (acertamos el 100%), pero en total, tenemos una menor precisión.



### Naive Bayes variables tipificadas
```{r}
NaiveBayes_trans = naiveBayes(formula = Class ~ .,data=train_trans)#Ajustamos modelo.
prob=predict(NaiveBayes_trans,test_trans,type = 'raw')[,2]#Estimamos probabilidades de test.
(evaluaciones=rbind(evaluaciones,evaluacion(test_trans$Class,prob,'NaiveBayes_trans')[[1]]))
```

Obtenemos exactamente los mismos resultados que con el anterior modelo, esto parece que se debe a que la tipificación no afecta al calculo de las probabilidades condicionadas.



### Análisis discriminante variables originales.

 Teoricamente se pide normalidad, de modo que usár factores no parece muy apropiado, pero podría funcionar.
```{r}
LDA=lda(Class~.,data=train)#Ajustamos modelo.
predicciones=predict(LDA,test)
prob=predicciones$posterior[,2]#Estimación probabilidades de test.
(evaluaciones=rbind(evaluaciones,evaluacion(test$Class,prob,'LDA')[[1]]))
```

Obtenemos unos resultados similares a los anteriores.



### Análisis discriminante variables numéricas
```{r}
LDA_num=lda(Class~.,data=train_num)#Ajustamos modelo.
predicciones=predict(LDA_num,test_num)
prob=predicciones$posterior[,2]#Estimación probabilidades de test.
(evaluaciones=rbind(evaluaciones,evaluacion(test_num$Class,prob,'LDA_num')[[1]]))
```

Empeoran ligeramente los resultados respecto al anterior modelo.



### Análisis discriminante variables tipificadas.
```{r}
LDA_trans=lda(Class~.,data=train_trans)#Ajustamos modelo.
predicciones=predict(LDA_trans,test_trans)
prob=predicciones$posterior[,2]#Estimación probabilidades de test.
(evaluaciones=rbind(evaluaciones,evaluacion(test_trans$Class,prob,'LDA_trans')[[1]]))
```

Parece que los dos ultimos modelos son iguales. Si miramos la construcción del modelo, comparabamos dos distancias (de Mahalanobis) entre el punto a clasificar y las medias de las dos clases. La desigualdad que indica cual de las distancias es mayor (que indica como clasificaremos) queda invariante al cambiar la escala.



##Ultimos apartados

###3. Determine el número de predicciones correspondientes a la clase malignant.
###4. De las predicciones consideradas en el apartado anterior, determine cuántas de ellas se han obtenido con una probabilidad mayor que 0.75.

Usaremos el modelo Naive Bayes construido con las variables originales. Veamos cuantas instancias del conjunto test predice como "malignant".
```{r}
prob=predict(NaiveBayes,test,type = 'raw')[,2]#Estimamos probabilidades de test.
sum(prob>0.5)
sum(prob>=0.5)#Comprobamos si hay algun elemento en la frontera.
```

Clasificamos $86$ instancias como "malignant". Veamos cuantas de ellas se han obtenido con una probabilidad mayor que 0.75.

```{r}
sum(prob>0.75)
```

Del total de instancias clasificadas como "malignant", $85$ se clasifican con una probabilidad mayor que 0.75. Recordemos la matriz de confusión de este modelo.

```{r}
evaluacion(test$Class,prob,'NaiveBayes',F)[[2]]
```

Se observa que de las clasificadas como "malignant", $5$ son incorrectas.

